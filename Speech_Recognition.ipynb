{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/around-star/Speech-Recognition/blob/main/Speech_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3WauAVwyBgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607ba3ed-da03-4c22-acad-991573b69659"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from itertools import groupby\n",
        "import pandas as pd\n",
        "import os\n",
        "import sklearn\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "import time\n",
        "!pip install jiwer\n",
        "from jiwer import wer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.24.1\n",
            "Collecting jiwer\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/cc/fb9d3132cba1f6d393b7d5a9398d9d4c8fc033bc54668cf87e9b197a6d7a/jiwer-2.2.0-py3-none-any.whl\n",
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jiwer) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein->jiwer) (50.3.2)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144791 sha256=40ad40ebd1fa48fa5f2fe4e6774f09433353a32e01b8d61c47c76817d86004e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.2.0 python-Levenshtein-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ogVI60q5GuY"
      },
      "source": [
        "## Subwords github repo clone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAQMtFsk5PVP",
        "outputId": "e0a4e31f-6ec1-44e8-d5c5-8b46ca468415"
      },
      "source": [
        "!git clone https://github.com/bheinzerling/bpemb.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bpemb'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 385 (delta 25), reused 30 (delta 13), pack-reused 338\u001b[K\n",
            "Receiving objects: 100% (385/385), 620.22 KiB | 1.85 MiB/s, done.\n",
            "Resolving deltas: 100% (221/221), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_sPF1oR-2u2",
        "outputId": "83482aaf-2ef4-442c-db27-c3fa315cb257"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 16.2MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 21.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 23.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 18.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 13.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 15.5MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 12.4MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 11.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 10.8MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 10.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 10.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 10.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 10.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 10.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 10.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 10.9MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Bi3X1q8Otz"
      },
      "source": [
        "from bpemb.bpemb import BPEmb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luihn6gr-mpR",
        "outputId": "015584ad-d09b-4375-9ceb-89be184142ef"
      },
      "source": [
        "bpemb_en = BPEmb(lang='en', dim = 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1924908/1924908 [00:00<00:00, 23865354.19B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.d50.w2v.bin.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nxKAYDH_Eep"
      },
      "source": [
        "bpemb_en.words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p6YVqOaHJVc"
      },
      "source": [
        "## Kaggle Common voice dataset download "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SuzDKwZHIbo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3a11a1-b1a7-4a9a-d20c-89bc1fedb330"
      },
      "source": [
        "!apt install kaggle\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"andr3w88\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"67e85b3d3f682d0ae9bda7a78dfa7df0\" # key from the json file\n",
        "\n",
        "!kaggle datasets download -d mozillaorg/common-voice # api copied from kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package kaggle\n",
            "Downloading common-voice.zip to /content\n",
            "100% 12.0G/12.0G [05:06<00:00, 51.9MB/s]\n",
            "100% 12.0G/12.0G [05:06<00:00, 42.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLBKZQnxZtep"
      },
      "source": [
        "!unzip -q common-voice.zip -d common-voice/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKDFFX0THT24"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5-8_wDqw7s_"
      },
      "source": [
        "**UTILS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZt1R6fswQ2c"
      },
      "source": [
        "def init_vocab():\n",
        "\n",
        "    alphabet = \"abcdefghijklmnopqrstuvwxyz'\"\n",
        "    alphabets = ['', ' '] + [c for c in alphabet]\n",
        "\n",
        "    return alphabets\n",
        "\n",
        "\n",
        "def load_audio(path):\n",
        "    \"\"\"Loads Audio and returns the vector\"\"\"\n",
        "    sound = AudioSegment.from_mp3(path)\n",
        "    sound = tf.cast(sound.get_array_of_samples(), tf.float32)\n",
        "    sampled_sound = [sound[x] for x in range(0, len(sound), 48)]\n",
        "    return sampled_sound\n",
        "\n",
        "\n",
        "def compute_mel_spec(audio_arr, sample_rate = 15200, n_mel_bins = 80, frame_length = 0.025, frame_stride = 0.001, hertz_low = 125.0, hertz_high = 7600.0):\n",
        "    sample_rate_f = tf.cast(sample_rate, tf.float32)\n",
        "\n",
        "    frame_length = tf.cast(tf.round(frame_length * sample_rate_f), tf.int32)\n",
        "    frame_stride = tf.cast(tf.round(frame_stride * sample_rate_f), tf.int32)\n",
        "\n",
        "    stfts = tf.signal.stft(audio_arr, frame_length = frame_length, frame_step = frame_stride)\n",
        "\n",
        "    mag_specs = tf.abs(stfts)\n",
        "    num_spec_bins = tf.shape(mag_specs)[-1]\n",
        "\n",
        "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(num_mel_bins = n_mel_bins, num_spectrogram_bins = num_spec_bins,\n",
        "                                                                        sample_rate = sample_rate_f, lower_edge_hertz = hertz_low,\n",
        "                                                                        upper_edge_hertz = hertz_high)\n",
        "\n",
        "    mel_specs = tf.tensordot(mag_specs, linear_to_mel_weight_matrix, 1)\n",
        "    mel_specs.set_shape(tf.concat([tf.shape(mag_specs)[:-1], tf.shape(linear_to_mel_weight_matrix)[-1:]], 0))\n",
        "\n",
        "    log_mel_specs = tf.math.log(mel_specs + 1e-6)\n",
        "    log_mel_specs -= (tf.reduce_mean(log_mel_specs, axis=0) + 1e-8) # Zero centered\n",
        "    #log_mel_specs = log_mel_specs / tf.math.reduce_std(log_mel_specs, axis = 0) # Standarization\n",
        "    \n",
        "    return log_mel_specs\n",
        "\n",
        "\n",
        "def ctc_greedy_decode(y_pred):\n",
        "    decoded = []\n",
        "\n",
        "    for i in range(np.shape(y_pred)[0]):\n",
        "        decoded_batch = []\n",
        "        for j in range(np.shape(y_pred)[1]):\n",
        "            c = np.argmax(y_pred[i][j])\n",
        "            decoded_batch.append(c)\n",
        "\n",
        "        temp = [k for k , g in groupby(decoded_batch)]\n",
        "        temp = [x for x in temp if x!=0]\n",
        "        \n",
        "        decoded.append(temp)\n",
        "\n",
        "    return decoded\n",
        "\n",
        "def joint(model, f, g):\n",
        "    dense_1 = model.layers[-2]\n",
        "    dense_2 = model.layers[-1]\n",
        "\n",
        "    joint = (tf.expand_dims(f, axis = 2) + tf.expand_dims(g, axis = 1))\n",
        "\n",
        "    outputs = dense_1(joint)\n",
        "    outputs = dense_2(outputs)\n",
        "\n",
        "    return outputs[0][0][-1][:]\n",
        "\n",
        "def rnnt_greedy_decode(model, input):\n",
        "    decoded = []\n",
        "    input = tf.expand_dims(input, axis=0)\n",
        "    encoder = model.layers[2]\n",
        "    prediction_network = model.layers[3]\n",
        "\n",
        "    start_token = tf.constant([0])\n",
        "\n",
        "    encoded = encoder(input)\n",
        "    enc_length = np.shape(input)[0]\n",
        "    output = np.expand_dims(start_token, axis = 0)\n",
        "    outputs = np.expand_dims(start_token, axis = 0)\n",
        "\n",
        "    time_cond = True\n",
        "    i = 0\n",
        "    while (time_cond):\n",
        "        inp_enc = tf.expand_dims(encoded[:][i][:], axis = 1)\n",
        "\n",
        "        dec_end = True\n",
        "        while (dec_end):\n",
        "            \n",
        "            pred_out = prediction_network(output)\n",
        "            \n",
        "            preds = joint(model, inp_enc, pred_out)\n",
        "\n",
        "            pred_id = tf.argmax(preds, axis=-1)\n",
        "            \n",
        "            if (pred_id == 0):\n",
        "                dec_cond = False\n",
        "            else :\n",
        "                outputs = np.concatenate([outputs, [[pred_id]]], axis = 1)\n",
        "                output = np.array([[pred_id]])\n",
        "        i+=1\n",
        "        if (i>=enc_length):\n",
        "            time_cond = False\n",
        "\n",
        "    return outputs      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J3vqlAwx4NI"
      },
      "source": [
        "**BATCH GENERATOR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSHNvh_DwxUt"
      },
      "source": [
        "\n",
        "class DataGen :\n",
        "    def __init__(self):\n",
        "        self.x_train = []\n",
        "        self.y_train = []\n",
        "        self.logit_length = []\n",
        "        self.label_length = []\n",
        "        \n",
        "\n",
        "    def create_char_data(self, path, csv_path, vocab):\n",
        "        train_csv = pd.read_csv(csv_path)\n",
        "        for i in range(len(train_csv[\"text\"])):\n",
        "            if (i>=200):\n",
        "                break\n",
        "            filename = train_csv.iloc[i][\"filename\"]\n",
        "            audio_vec = load_audio(os.path.join(path, filename))\n",
        "            feature_vec = compute_mel_spec(audio_vec)\n",
        "            self.x_train.append(feature_vec)\n",
        "            label = train_csv.iloc[i][\"text\"]\n",
        "            labels = [vocab.index(j) for j in label]\n",
        "            self.y_train.append(labels)\n",
        "            self.label_length.append(len(label))\n",
        "            self.logit_length.append(np.array(feature_vec).shape[0])\n",
        "\n",
        "        #self.x_train = self.pad_feature(self.x_train)\n",
        "        #self.y_train = self.pad_label(self.y_train)\n",
        "\n",
        "    def create_wordpiece_data(self, path, csv_path):\n",
        "        train_csv = pd.read_csv(csv_path)\n",
        "        labels = []\n",
        "        for i in range(len(train_csv[\"text\"])):\n",
        "            if (i>=100):\n",
        "                break\n",
        "            filename = train_csv.iloc[i][\"filename\"]\n",
        "            audio_vec = load_audio(os.path.join(path, filename))\n",
        "            feature_vec = compute_mel_spec(audio_vec)\n",
        "            self.x_train.append(feature_vec)\n",
        "            label = train_csv.iloc[i][\"text\"]\n",
        "            labels.append(label)\n",
        "            self.logit_length.append(np.array(feature_vec).shape[0])\n",
        "\n",
        "        tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "        tokenizer.fit_on_texts(labels)\n",
        "        self.y_train = tokenizer.texts_to_sequences(labels)\n",
        "        self.label_length = [len(label) for label in self.y_train]\n",
        "        return tokenizer\n",
        "\n",
        "    def create_subwordpiece_data(self,path, csv_path):\n",
        "          \n",
        "        train_csv = pd.read_csv(csv_path)\n",
        "        for i in range(len(train_csv[\"text\"])):\n",
        "            if (i>=100):\n",
        "                break\n",
        "            filename = train_csv.iloc[i][\"filename\"]\n",
        "            audio_vec = load_audio(os.path.join(path, filename))\n",
        "            feature_vec = compute_mel_spec(audio_vec)\n",
        "            self.x_train.append(feature_vec)\n",
        "            label = train_csv.iloc[i][\"text\"]\n",
        "            labels = bpemb_en.encode(label)\n",
        "            labels = [bpemb_en.words.index(j) for j in label]\n",
        "            self.y_train.append(labels)\n",
        "\n",
        "    def steps_per_epoch(self, batch_size = 32):\n",
        "        return len(self.x_train)//batch_size\n",
        "\n",
        "    def next_batch(self, batch_size=32):\n",
        "\n",
        "        current = 0\n",
        "\n",
        "        while True:\n",
        "\n",
        "            if (current + batch_size >= len(self.x_train)):\n",
        "                current = 0\n",
        "\n",
        "            self.x_train, self.logit_length, self.label_length, self.y_train= sklearn.utils.shuffle(self.x_train, self.logit_length, self.y_train, self.label_length)\n",
        "\n",
        "            batch_y = self.y_train[current : current + batch_size]\n",
        "            batch_logit_length = self.logit_length[current : current + batch_size]\n",
        "            batch_label_length = self.label_length[current : current + batch_size]\n",
        "            batch_x = self.x_train[current : current + batch_size]\n",
        "\n",
        "            current += batch_size\n",
        "            \n",
        "            ret = []\n",
        "            ret.append(batch_x)\n",
        "            ret.append(batch_logit_length)\n",
        "            ret.append(batch_y)\n",
        "            ret.append(batch_label_length)\n",
        "            yield ret\n",
        "\n",
        "    def pad_feature(self, x):\n",
        "      max_len = max(self.logit_length)\n",
        "      pad_features = []\n",
        "\n",
        "      for i in range(len(x)):\n",
        "        len_lag = max_len - self.logit_length[i]\n",
        "        arr_lag = np.zeros((len_lag, np.shape(x[i])[-1]))\n",
        "        pad_feature = np.concatenate((x[i], arr_lag))\n",
        "        pad_features.append(pad_feature)\n",
        "\n",
        "      return pad_features\n",
        "\n",
        "    def pad_label(self, y):\n",
        "      max_len = max(self.label_length)\n",
        "      pad_labels = []\n",
        "\n",
        "      for i in range(len(y)):\n",
        "        len_lag = max_len - self.label_length[i]\n",
        "        arr_lag = np.zeros((len_lag), dtype=np.int64)\n",
        "        pad_label = np.concatenate((y[i], arr_lag))\n",
        "        pad_labels.append(pad_label)\n",
        "\n",
        "      return pad_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFJIkBWa17iE"
      },
      "source": [
        "**MODEL CTC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGxBHwos2AQJ"
      },
      "source": [
        "n_mel_bins = 80\n",
        "\n",
        "def build_model(vocab_size, n_mel_bins=80, num_layers = 3):\n",
        "    mel_specs = tf.keras.layers.Input(shape=[None, n_mel_bins])\n",
        "    norm_mel_specs = tf.keras.layers.LayerNormalization(name='norm0')(mel_specs)\n",
        "\n",
        "    output = norm_mel_specs\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        output = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True, name = 'lstm{}'.format(i)))(output)\n",
        "        output = tf.keras.layers.LayerNormalization(name='norm{}'.format(i+1))(output)\n",
        "\n",
        "    output = tf.keras.layers.Dropout(0.3, name = 'dropout1')(output)\n",
        "    output = tf.keras.layers.Dense(vocab_size, name = 'dense1')(output)\n",
        "\n",
        "    model =  tf.keras.Model(inputs = mel_specs, outputs = output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTjesNF-2GlU"
      },
      "source": [
        "**MODEL RNNT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjhn_NaW2JxZ"
      },
      "source": [
        "def conv_layers(shape):\n",
        "    input = tf.keras.layers.Input(shape = shape)\n",
        "    input = tf.expand_dims(input, axis = -1)\n",
        "    conv1 = tf.keras.layers.Conv2D(1, (3, shape[-1]))(input)\n",
        "    conv1 = tf.reshape(conv1, shape=tf.shape(conv1)[:-1])\n",
        "    return conv1\n",
        "\n",
        "def encoder(specs_shape, num_layers = 3):\n",
        "    mel_specs = tf.keras.layers.Input(shape = specs_shape)\n",
        "    norm_mel_specs = tf.keras.layers.BatchNormalization()(mel_specs)\n",
        "\n",
        "    output = norm_mel_specs\n",
        "    \n",
        "    for i in range(num_layers):\n",
        "        output = tf.keras.layers.LSTM(2048, return_sequences=True)(output)\n",
        "        output = tf.keras.layers.Dropout(0.3)(output)\n",
        "        output = tf.keras.layers.LayerNormalization()(output)\n",
        "\n",
        "    return tf.keras.Model(inputs = mel_specs, outputs = output)\n",
        "\n",
        "def prediction_network(vocab_size, embed_size, num_layers = 1, dropout = 0.2):\n",
        "    inputs = tf.keras.layers.Input(shape= [None])\n",
        "\n",
        "    embed = tf.keras.layers.Embedding(vocab_size, embed_size)(inputs)\n",
        "\n",
        "    output = embed\n",
        "    for _ in range(num_layers):\n",
        "        output = tf.keras.layers.LSTM(2048, return_sequences = True)(output)\n",
        "        output = tf.keras.layers.Dropout(dropout)(output)\n",
        "        output = tf.keras.layers.LayerNormalization()(output)\n",
        "\n",
        "    return tf.keras.Model(inputs = inputs, outputs = output)\n",
        "\n",
        "def build_keras_model(vocab_size, n_mel_bins = 80, embed_size = 500, reduction_factor = 3):\n",
        "\n",
        "    mel_specs = tf.keras.layers.Input(shape = [None, n_mel_bins])\n",
        "    pred_inp = tf.keras.layers.Input(shape = [None])\n",
        "\n",
        "    inp_enc = encoder(specs_shape = [None, n_mel_bins])(mel_specs)\n",
        "    pred_outputs = prediction_network(vocab_size = vocab_size, embed_size = embed_size)(pred_inp)\n",
        "\n",
        "    joint_layer = (tf.expand_dims(inp_enc, axis = 2) + tf.expand_dims(pred_outputs, axis = 1))\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(640, activation = 'tanh')(joint_layer)\n",
        "    outputs = tf.keras.layers.Dense(vocab_size, activation = 'softmax')(outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs = [mel_specs, pred_inp], outputs = outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpnkWWqfzRgD"
      },
      "source": [
        "**LOSS RNNT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiEyyVP3y1rd"
      },
      "source": [
        "def forward_pass(log_probs, labels):\n",
        "\n",
        "    T, U, _ = np.shape(log_probs)\n",
        "    alphas = np.zeros((T, U))\n",
        "\n",
        "    for t in range(1, T):\n",
        "        alphas[t][0] = alphas[t-1][0] + log_probs[t-1][0][0]\n",
        "\n",
        "    for u in range(1, U):\n",
        "        \n",
        "        alphas[0][u] = alphas[0][u-1] + log_probs[0][u-1][labels[u-1]]\n",
        "\n",
        "    for t in range(1, T):\n",
        "        for u in range(1, U):\n",
        "            \n",
        "            no_emit = alphas[t-1][u] + log_probs[t-1][u][0]\n",
        "            emit = alphas[t][u-1] + log_probs[t][u-1][labels[u-1]]\n",
        "            alphas[t][u] = np.logaddexp(no_emit, emit)\n",
        "\n",
        "    loglike = alphas[T-1][U-1] + log_probs[T-1][U-1][0]\n",
        "\n",
        "    return -loglike\n",
        "\n",
        "def loss_rnnt(log_probs, labels):\n",
        "\n",
        "    costs = []\n",
        "\n",
        "    for b in range(len(log_probs)):\n",
        "        #t = f_len[b]\n",
        "        #u = g_len[b] + 1\n",
        "        loss = forward_pass(log_probs[b], labels[b])\n",
        "        \n",
        "        costs.append(loss)\n",
        "\n",
        "    costs = tf.reduce_mean(costs)\n",
        "    return costs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbSLSKurzqNI"
      },
      "source": [
        "**TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xuUV14X9EIO"
      },
      "source": [
        "#vocab = init_vocab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJRyOsJZfca-"
      },
      "source": [
        "\n",
        "path = \"common-voice/cv-valid-train\"\n",
        "csv_path = \"common-voice/cv-valid-train.csv\"\n",
        "\n",
        "train = DataGen()\n",
        "tokenizer = train.create_wordpiece_data(path, csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RfdNrqgeAoD"
      },
      "source": [
        "batch_size = 5\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "steps_per_epoch = train.steps_per_epoch(batch_size)\n",
        "generator = train.next_batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETBCchPUUI1E"
      },
      "source": [
        "#model_ctc = build_model(len(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKgDjqdU5qpv"
      },
      "source": [
        "vocab_len = len(tokenizer.word_index.items()) + 1 # for wordpiece model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrnFgtBAoFvs"
      },
      "source": [
        "model_rnnt = build_keras_model(vocab_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9RfOOL8zYnS"
      },
      "source": [
        "def run_train(n_epochs,model, steps_per_epoch, model_type = 'ctc'):\n",
        "\n",
        "    if (model_type == 'ctc'):\n",
        "\n",
        "        model_name = 'model_ctc'\n",
        "\n",
        "        model = build_model(len(vocab))\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            for step in range(steps_per_epoch):\n",
        "\n",
        "                data = next(generator)\n",
        "                features, logit_length, labels, label_length = data[0], data[1], data[2], data[3]\n",
        "\n",
        "                with tf.GradientTape() as tape:\n",
        "                    logits = model(features)\n",
        "                    loss = tf.nn.ctc_loss(labels, logits, label_length, logit_length, logits_time_major=False)\n",
        "                    loss = tf.reduce_mean(loss)\n",
        "\n",
        "                gradients = tape.gradient(loss, model.variables)\n",
        "\n",
        "                optimizer.apply_gradient(zip(gradients, model.variables))\n",
        "\n",
        "                if step % 25 == 0 and step != 0 :\n",
        "                    print(\"Epoch {} , Step {} , Loss {}\".format(epoch, step, loss))\n",
        "\n",
        "            if epoch % 10 == 0 and epoch != 0:\n",
        "                model.save_weights('weights/{}_epoch_{}'.format(model_name, epoch))\n",
        "\n",
        "    elif (model_type == 'rnnt'):\n",
        "        \n",
        "        model_name = 'model_rnnt'\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            for step in range(steps_per_epoch):\n",
        "                start = time.time()\n",
        "                data = next(generator)\n",
        "                #features, f_len, labels, g_len = np.array(data[0]), data[1], np.array(data[2]), data[3]\n",
        "                features, labels = data[0], data[2]\n",
        "                \n",
        "                with tf.GradientTape() as tape:\n",
        "                    y_pred = []\n",
        "                    for b in range(len(labels)):\n",
        "                      feature = np.expand_dims(features[b], axis = 0)\n",
        "                      label = [0] + labels[b]\n",
        "                      pred_input = np.expand_dims(label, axis = 0)\n",
        "                      probs = model([feature, pred_input])[0]\n",
        "                      log_probs = tf.math.log(probs)\n",
        "                      y_pred.append(log_probs)\n",
        "                    \n",
        "                    loss = loss_rnnt(y_pred, labels)\n",
        "                gradients = tape.gradient(loss, model.variables)\n",
        "                optimizer.apply_gradients(zip(gradients, model.variables))\n",
        "                print(time.time() - start)\n",
        "                print(\"Epoch {} , Step {} , Loss {}\".format(epoch, step, loss))\n",
        "            \n",
        "            if epoch % 10 == 0 and epoch != 0:\n",
        "                model.save_weights('weights/{}_epoch_{}'.format(model_name, epoch))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66x_k2Gt0dJW"
      },
      "source": [
        "**CTC TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4M_a9gTz51m"
      },
      "source": [
        "def evaluate(x_test):\n",
        "\n",
        "    vocab = init_vocab()\n",
        "    model = build_model(len(vocab))\n",
        "\n",
        "    model.load_weights('weights/model_ctc_30')\n",
        "\n",
        "    dim = len(np.shape(x_test))\n",
        "    if (dim == 2):\n",
        "        mel_feature = compute_mel_spec(x_test)\n",
        "        x = np.expand_dims(mel_feature, axis=0)\n",
        "    elif (dim == 3):\n",
        "        x = []\n",
        "        for i in x_test:\n",
        "            mel_feature = compute_mel_spec(i)\n",
        "            x.append(mel_feature)\n",
        "\n",
        "    y_pred = model(x)\n",
        "    decoded_y_pred = ctc_greedy_decode(y_pred)\n",
        "\n",
        "    return decoded_y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Sh6lqpn1UZC"
      },
      "source": [
        "**RNNT TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBO00OclovrV"
      },
      "source": [
        "#Tokenize/Wordpiece test\n",
        "reverse_word_map = dict (map(reversed, tokenizer.word_index.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmpM-C4d1Tdb"
      },
      "source": [
        "def evaluate(x_test, reverse_word_map, wordpiece = True):\n",
        "    vocab = init_vocab()\n",
        "    model = build_keras_model(len(vocab))\n",
        "\n",
        "    model.load_weights('weights_path')\n",
        "    y_pred = []\n",
        "    \n",
        "    for i in x_test:\n",
        "        pred_text = \"\"\n",
        "        mel_feature = compute_mel_spec(i)\n",
        "        y_decoded = rnnt_greedy_decode(model, mel_feature)\n",
        "        if wordpiece:\n",
        "          y_decoded = [reverse_word_map[index] for index in y_decoded]\n",
        "        for index in y_decoded:\n",
        "            pred_text = pred_text + \" \"\n",
        "        y_pred.append(pred_text[:-1])\n",
        "\n",
        "    y_pred = rnnt_greedy_decode(model, x)\n",
        "    \n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2M1-830a922"
      },
      "source": [
        "def eval_wer(path, tokenizer, csv_path, reverse_word_map):\n",
        "  test_csv = pd.read_csv(csv_path)\n",
        "        labels = []\n",
        "        x_test = []\n",
        "        for i in range(len(test_csv[\"text\"])):\n",
        "            if (i>=100):\n",
        "                break\n",
        "            filename = test_csv.iloc[i][\"filename\"]\n",
        "            audio_vec = load_audio(os.path.join(path, filename))\n",
        "            x_test.append(audio_vec)\n",
        "            label = test_csv.iloc[i][\"text\"]\n",
        "            labels.append(label)\n",
        "\n",
        "        y_pred = evaluate(x_test, reverse_word_map)\n",
        "        return wer(labels, y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}